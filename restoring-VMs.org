on. 20. nov. 21:44:34 +0100 2019
Wed 04 Dec 2019 11:26:22 AM CET


After moving everything to the nvme ssd the VM files got erased. Next
time I will back them up too.

VMs have to get recreated, so that I can have the fleet to work
with. Some work was done already as the Vagrant files were saved. It's
a pity that they only contained info about hostnames and IPs. I've
modified provisioning script inside Vagrantfile to run `yum update -y`
to ugprade the VMs to the latest version of all software. Can't trust
the network with the smart TV on it.

Osticket VM has gone trough the recreation process and already had a
provisioning script created. The script downloaded the osticket app,
set it up, including a pause to finish the installation trough a web
browser. Not sure if the script configured postfix properly, this
needs to be verified. 

* DONE Osticket
  CLOSED: [2019-11-23 lø. 16:39]
** Check if postfix works. Upgrade the script, so it can be reused.
** Trying changing the owner of /etc/postfix to postfix
https://serverfault.com/a/463770
This answer suggests, that the problem is caused by postfix not owning
the postfix directory.

Trying to fix it with sudo chown postfix /etc/postfix

The postmap command worked.

Email got sent sucessfully, though it required extra work on blur page
to get it, and then another extra resend to the gmail account.

** sasl_passwd.db file still contains the password.
  <Ignacy> I'm trying to configure postfix to use a password hash (.db
file) to authenticate with 3rd party smpt provider. I've looked at
hash created with postmap command, and except for hash it still
contains cleartext password at the end of the hash. Is that supposed
to be like that? If someone is to get root access to the machine he
can still read my 3rd party mail provider password.
  <ryuo> Ignacy:
... password hashs don't work when you have to provide the password to
an external party for authentication purposes.
  <ryuo> Ignacy: they're
only good for when you only need to store them for your authentication
purposes.
  <ryuo> Ignacy: welcome to the limitations of encyption.
  <ryuo> automated tools rarely have a good way to store authentication
secrets; you usually have to store them in a secure manner but can't
eliminate disclosure entirely.
  <ryuo> usually this means putting them
in a file that most cannot access.
  <ryuo> not storing it in revision
control system
  <ryuo> etc
* DONE Kanboard
  CLOSED: [2019-11-23 lø. 18:05]
** See where the provisioning script can be modified and modify it.
Parts like installing MariaDB and securing it, and also postfix
configuration, can surely be reused. Kanboard specific settings have
to be modified.
** Edit the script to use some variables and modify it along project.pdf

Final version of the script in a new submenu.
It "mostly" works, except for the mysql_secure_installation, not sure
of that.
And it's not indempotent. This fancy word I've learned from the
beggining of Ansible book by James Turnbul. It is an idea, that
commands run against a server should work the first time they are run
(like my script) but also second and any other. We should really
declare a state we expect, not the actions.

This script is not indempotent. While debugging, I've run it several
times. Some commands, like yum, worked several times, without giving
errors (as there were no errors if the packages were installed, the
result was correct - required packages were on the system). Other
commands had to be commented (#) out, or else script would stop (used
set -e to make it stop in case something didn't work). There should
probably be checks and conditionals connected with them to avoid
running actions that have already been run. I'm not sure if it's worth
detouring for that, I will most likely learn how to do all these
things with ansible, which is better suited for indempotent
configuration management.

*** Script in the final form, it most likely works.

#! /bin/bash
# Moved Vagrant files which messed up osticket project.
# Extracting history to make a provisioning script.
set -e
sudo yum update -y 

# Installing Apache
sudo yum install -y httpd php php-mysql 
sudo yum install -y php-gd php-xml php-mbstring

sudo systemctl enable --now httpd

# DB
DBNAME=kanboard
DBUSER=kanboard
DBUSER_PASSWD=kanboard123
sudo yum install -y mariadb-server && sudo systemctl enable --now mariadb
echo -e '\n\nroot123\nroot123\n\n\n\n' | sudo mysql_secure_installation 
sudo mysqladmin -u root -proot123 create $DBNAME
sudo mysql -u root -proot123 -D $DBNAME -e "grant all on ${DBNAME}.* to ${DBUSER}@localhost identified by '${DBUSER_PASSWD}' ; flush privileges;"

# Files
curl -LO http://mirror.linuxtrainingacademy.com/kanboard/kanboard-v1.0.34.zip
unzip kanboard-v1.0.34.zip
sudo mv kanboard/* /var/www/html
ls -l /var/www/html
#Tell the app how to connect to database
sudo tee -a /var/www/html/config.php <<EOF
<?php
define('DB_DRIVER', 'mysql');
define('DB_USERNAME', 'kanboard');
define('DB_PASSWORD', 'kanboard123');
define('DB_HOSTNAME', 'localhost');
define('DB_NAME', 'kanboard');
EOF

# postfix
sudo yum install cyrus-sasl-plain -y #SASL auth lib
sudo cp /etc/postfix/main.cf /etc/postfix/main.cf.orig
sudo tee -a /etc/postfix/main.cf <<EOF
"smtp_sasl_auth_enable = yes
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_sasl_security_options = noanonymous
smtp_sasl_tls_security_options = noanonymous
smtp_tls_security_level = encrypt
header_size_limit = 4096000
relayhost = [smtp.sendgrid.net]:587"
EOF
sudo cp /vagrant/sasl_passwd /etc/postfix/sasl_passwd
sudo chmod 600 /etc/postfix/sasl_passwd
sudo postmap /etc/postfix/sasl_passwd
sudo systemctl restart postfix.service
sudo rm -f /etc/postfix/sasl_passwd
   
* DONE Fxing Vagrant ssh error
  CLOSED: [2019-12-03 Tue 10:11]
It took me a long time to fix. There was a change in the configuration
of the /etc/ssh/ssh_config file. This file is responsible for the
default settings of the ssh CLIENT. At the bottom of the file there
was an extra line GSSAPIauth yes, which enabled some kerberos style
authentication.

This modification stood out, being at the end of the file. It lacked a
proper comment with date and name of the administrator modifying the
file. There could also have been a comment about why the change was
made. To further prevent such errors there will be made a
"maintenance.org" file, where I will document changes to my personal
computer.

Even though the change was easy to notice, first attempt to verify if
this was the reason of problems failed. After modyfing the file I've
reloaded the sshD deamon. This was an error. Problem ocurred when
logging from the machine, not into it. That meant that the program
managing connections from the machine was at fault, ssh client, not
the program managing incoming connections, the ssh daemon.
systemctl restart sshd.service reloaded files working with the
daemon. The ssh.service should've been restarted/reloaded instead.

After getting frustrated I've started digging at the problem and
stopped taking regular brakes and documenting tried solutions. Being
tired and not documenting what I've been doing might have added to the
reasons why the error took couple days to fix.
* DONE Icinga (with Icinga Web 2.4)
  CLOSED: [2020-01-05 Sun 20:17]
With icinga not only the web-app has to be installed, but also other
VMs have to be configured to feed Icinga with data. 
** Install Icinga server and web-app.
*** Renamed the provisioning script to icinga
*** modified the script to use the mysql .sql script to secure the database
sudo mysql -uroot < mysql_secure_installation.sql
*** Added PHP support (learned from icinga docs)
Looks like there is an easier way to get icinga supported with the
required PHP packages, and that's the way that the application expects
from server.
https://icinga.com/docs/icingaweb2/latest/doc/02-Installation/#installation

yum install centos-release-scl

*** Modified the script to use the right php packages
sudo yum install -y httpd php php-gd php-intl php-ldap \
     php-ZendFramework php-ZendFramework-Db-Adapter-Pdo\
     -Mysql php-pecl-imagick
*** Added PHP configuration
What I like here is that the script will create a different php.ini
backup file for each minute after the beggining of current epoch 1st
Jan 1970.

sudo cp /etc/php.ini /etc/php.ini.bak-$(($(date +%s)/60))
echo "date.timezone = \"Europe/Oslo\"" | sudo tee -a /etc/php.ini

**** To avoid having an extra line with timezone
After each run of the script, I will check if the line is present, and
only run the modification if the line is missing from the
configuration file.

***** Check if the line is there
grep -q 'date.timezone = "Europe/Oslo"' /etc/php.ini

***** Put it in an if statement
I've spent one (edit: several) pomodoro reading on if statements from:
about:reader?url=https%3A%2F%2Fmywiki.wooledge.org%2FBashGuide%2FTestsAndConditionals


if [ ! $(grep -q 'date.timezone = "Europe/Oslo"' /etc/php.ini) ]
then {
sudo cp -v /etc/php.ini /etc/php.ini.bak-$(($(date +%s)/60))
echo "date.timezone = \"Europe/Oslo\"" | sudo tee -a /etc/php.ini
}
else echo "Timezone already set."
fi

*** Securing MariDB installation
Script is `set -e` so it would stop execution when it encounters
erros, so that the script wouldn't run amok when the inevitable bug
will find it's way into it.
Since running the script for a second time would cause an error which
would stop the script execution, I asked on #bash for a way to stop it
for a moment. Ofcourse instead of giving an advice I was pointed to a
faq page that existed on this topic:
https://mywiki.wooledge.org/BashFAQ/105


**** So this is why set -e shouldn't be used in real scripts:
# set -e; true && (echo "hi"; exit 17); echo "I live, and exit status
# is $?"

set -e will go bonkers when using a subshell. It's ok for the
debugging a non production script, but production stuff will likely
start using subshells at some point. Better to catch errors in another
way.
**** I'll just use the example of what's not supposed to be used, as quoted
here:
But, if you're a certain type of person, maybe you think it's OK to
use set -e as long as you remember that you have to put "|| true" after
every single arithmetic command, and so on, and so on.
**** || true will stop set -e from stopping the script

*** Create Databases
Here I'm sending a heredocs as input to mysql -u root
sudo mysq -v -u root -proot123 <<EOF
create database if not exists icinga;
create database if not exists icingaweb;
EOF

*** Create DB Users

Just copied the same thing twice, but replaces variables :D
DBNAME=icinga
DBUSER=icinga
DBUSER_PASSWD=icinga123
sudo mysql -v -u root -proot123 -D $DBNAME -e \
     "grant all on ${DBNAME}.* to ${DBUSER}@localhost identified\
 by '${DBUSER_PASSWD}' ; "

DBNAME=icingaweb

DBUSER=icingaweb
DBUSER_PASSWD=icingaweb123
sudo mysql -v -u root -proot123 -D $DBNAME -e \
     "grant all on ${DBNAME}.* to ${DBUSER}@localhost identified\
 by '${DBUSER_PASSWD}' ; flush privileges;"

*** Configure Icinga repository
sudo yum install -y \
     http://mirror.linuxtrainingacademy.com/icinga/icinga-rpm-release-7\
     -1.el7.centos.noarch.rpm
*** Install Icinga
sudo yum install -y icinga2 icingaweb2 icingacli icinga2-ido-mysql
*** Configure Icinga Database
To avoid re-running the .sql we count the lines in mysqlshow output.

if [ $(mysqlshow -u root -proot123 icinga | wc -l) -eq 5 ]
then
mysql -v -u root -proot123 icinga < /usr/share/icinga2-ido-mysql/schema/mysql.sql
elif [ $(mysqlshow -u root -proot123 icinga | wc -l) -eq 66 ]
then {
echo "Database already initialized"
sleep 1;}
else {
echo "Database length neither 5 or 66, something's wrong?"
exit 1
}
fi

*** Tell icinga how to connect to the database (and cool SED stuff)
The file /etc/icinga2/features-available/ido-mysql.conf should be
edited. First, the leading forward slashes have to be removed. Then,
the password should be changed from icinga to icinga123.

Had to use Extended Regular Expressions in sed to allow alteration.
***** Script:
mystring="password = \"icinga123\""
my_url="/etc/icinga2/features-available/ido-mysql.conf"
if [ $(grep -c "$mystring" "$my_url" ) -lt 1 ]
then {
sudo sed -E -i.bak-$(($(date +%s)/60)) -e '/\/\/(us|pa|ho|da)/s/\/\///' -e '/password/s/inga/inga123/'
}
else echo "DB password in icinga already set."
fi
***** Sed -i option:
Here there is a fancy usage of sed -i option, that creates backup
files that change it's name every minute. Just to avoid the case, when
we create a backup of a botched file that would replace the good
backup.
***** Sed -E option:
Another new sed option is -E which turns on Extended Regular
Expressions. In contrast to Basic Regular Expressions, BRE, ERE allow
using alteration like (this|or|that). This way we limit number of
affected lines to those that were originally meant to be modified.
***** Sed -e option:
-e option just allows to put many sed expressions inside of a one sed
call. 


*** Allow commands to be received by the web front end
Icinga is modular, so you can enable different modules, which they
call features. We want to enable the "command" feature so the web
front end can send commands to Icinga such as acknowledging service
and host problems. We can verify running modules with feature list command:
**** sudo icinga2 feature enable command
**** sudo icinga2 feature list

*** Install Monitoring Plugins
After installing the service, we want to monitor hosts and apps.
Because Icinga is a fork of Nagios, we can use it's monitoring
plugins. 
sudo yum install -y nagios-plugins-all

*** Prepare the Server for Clients
This process has to be completed once if you will be using an Icinga
client installed locally on the machines you plan to monitor.

To prepare this server for that purpose we will run the node
wizard. This is master setup, therefore we answer 'n' to the first
question and then accept defaults by pressing enter for the following
questions.

sudo icinga2 node wizard <<EOF
n



EOF

*** Configure the Web Front-End
Here we have to get a token and use web browser to configure the Web
Front-End. I will copy wait option from osticket script.

# here you use the browser to configurate the app
read -n1 -r -p "Open http://10.23.45.30/icingaweb2/setup. Press space to continue..." key
echo "$key" # to avoid wrath of the linter program

*** Need to configure php-fpm and change some stuff.
After icinga upgraded itself to 2.11, there are some issues. The line
enabling the scl repository is not enough :(

*** Development of this version is paused, moving to icinga 2.11
* DONE Icinga (with Icinga Web 2.11
  CLOSED: [2020-01-04 Sat 20:06]
While installing the Icinga I've encountered some problems, mainly:
Icinga will update itself to version 2.11, which changes many
things. Most important is that Icinga Web 2.11 requires new version of
php. I've decided to use the Icinga documentation to make the
provisioning script anew. Most of the code can be reused, and what is
specific to Icinga 2.11 has to be extracted from the docs.

This is for the better, as the real life usage would require the
latest Icinga version, with latest security patches. 

** Reading the Icinga installation docs, looking for deviations.
The order in which things are done differs between Jason's
documentation and what's on Icinga web-page. Other than that tho, I
haven't found any difference in Icinga installation.

** Trying to implement the differences in newer Icinga Web installation
Usage of php 7.1 from SCL repo changes things a little bit. Will have
to run the script several times to make sure that everything
works. Would be best with a clean VM, without regular php. Required
php packages will be pulled by Icinga installation. I'm not sure where
the php.ini will be sitting, some candidates for that are in the
documentation.

** Added php-fpm installation lines from Icinga docs
It works now!
** Rewritten Configure PHP to add timezone to both php locations
Forgot to add $ in fron of where the php_path1,2 variables were used 
** Fixed indentation

** Fixed bug in heredocs postfix configuration
Postfix configuration was being entered into the configuration file
with quotes around it. Too much indentation on the first of heredocs
has revealed the mistake.

** Script works until setting up icinga web.
** Coment/uncomment in icinga's hosts.conf
** DONE Icinga host server doesn't show up.
   CLOSED: [2020-01-04 Sat 18:44]
The reason for the server not showing up is a difference in
configuration. The new configuration wizard WILL NOT, if re-run,
re-instate loading of configuration files from config directory conf.d
in /etc/icinga2. As a consequence, the files in conf.d wont' be
read. I wonder what was the reason to add that option and to set it as
the default action.

Have to reinstall icinga and check if it works if the wizard config in
the script is fixed.

It works now, after modifying the setup wizard to send an 'n' instead
of the last enter.
<<<<<<< HEAD
** why:
=======


*** why:
>>>>>>> 437bd2f4aa82587c7f787a193cfa0418ead945dd
In the file that configures what is being checked for which host,
there are lines responsible for monitoring the web server from
outside. After installation of icinga web, the 3 lines should be
commented and 3 lines that check for a web server hosting icinga
should be uncommented. 
*** Using sed to {un,}comment the lines
# First backup hosts.conf if not backed up last hour
conf_loc="/etc/icinga2/conf.d/hosts.conf"
if [ -e ${conf_loc}.$(($(date +%s)/60*60)) ]; then
else cp conf_loc conf_loc.$(($(date +%s)/60*60))
fi
sed -Ei "/^vars\.http.*http/,+2 s/^/\/\//" $conf_loc
*** Had to add a space to the regexp 
The reg exp worked when I tested it in shell. It didn't work the
second time. A space was at fault. After adding \s at the beginning,
after the caret sign, it started working again. The new regexp is
this:
sed -Ei "/^\s*vars\.http.*http/,+2 s/^/\/\//" $conf_loc
Here the \s means a whitespace character. It can be a space ( ), tab
\t, or one more option that I didn't remember. * means that it can
occur any number of times, including 0.
*** Learning how to make sed put the comments AFTER the indentation
Want to check online docs before I ask in #bash.
https://www.gnu.org/software/sed/manual/html_node/Regular-Expressions.html
s/^[X[:space:]]*/&\/\/ (Without the 'X')
The [ [:space:]]* matches any number of spaces at the beginning and &
references the whole matched part of the line aka pattern space in sed
talk.
However, this will put the slashes like that
  //
    //
  //
Which is ugly. I want them to be at the same distance from the margin,
so they will just be put after two spaces.
sed -E "/^\s*vars\.http.*http/,+2 s/^\ \ /&\/\//" $conf_
* Configure other VMs to feed data into Icinga 
** Configure checks on osticket:
*** Add osticket in hosts.conf file
**** DONE Add the basic Host info to hosts.conf
     CLOSED: [2020-01-05 Sun 20:18]
sudo nano /etc/icinga2/conf.d/hosts.confAdd the following lines to the
bottom of the file and save it.object Host "osticket" {  import
"generic-host"  address = "10.23.45.20"  vars.os = "Linux"}

** Prepare the server for the client 
*** Create a ticket with icinga for osticket
sudo icinga2 pki ticket --cn 'osticket'
*** Install icinga client on Osticket server
**** Install Icinga repo
yum install -y https://packages.icinga.com/epel/icinga-rpm-release-7-latest.noarch.rpm
**** Install epel (was installed on Osticket)
yum install -y epel-release
**** Install Icinga and Nagios plugins
yum install -y icinga2 nagios-plugins-all
**** Run Icinga node wizard && enable Icinga
sudo icinga2 node wizard <<EOF
ent
ent
icinga
ent
10.23.45.30
ent
ent
y
<ticket from icinga>
ent
ent
y
y
ent (local zone name: osticket)
ent (parent zone name: master)
ent (don't specify additional global zones)
n (because I don't want to disable the inclusion of conf.d directory)
EOF
systemctl enable --now icinga2
** Add additional monitors for the client on the server
On Icinga server edit /etc/icinga2/zones.conf:
appent the following to the end of the file:

object Endpoint "osticket" {
  host = "10.23.45.20"
}

object Zone "osticke" {
  endpoints = [ "osticket" ]
  parent = NodeName
}

And the following to /etc/icinga2/conf.d/hosts.conf:

object Service "load" {
  import "generic-service"
  check_command = "load"
  host_name = "osticket"
  command_endpoint = "osticket"
}

The above creates a new service check called load. It imports the
default configuration for service type objects with import
"generic-service". The load command is probably some icinga or nagios
predefined check. The check is run on the machine osticket, and
because we want to check something that's inside of the machine, we
tell icinga to run the check from a special endpoint that is in this
case the osticket machine itself.

After modifying the files we need to restart the icinga service.
** Config error - command_endpoint = "osticket"
Something wrong with this specific line in hosts.conf

I've commented the line telling icinga to run the load test from
within osticket. Suprisingly enough, the test worked.

Well, the test worked, but the results were the same for both icinga
and osticket. In web UI it even said that the test's source was
icinga. There was another config file edited today, and it was done on
the bus. I've made a typo and when defining osticket zone, I've
misspelled osticket like this:
object Zone "osticke" {
  endpoints = [ "osticket" ]
  parent = NodeName
}

*** TODO Error must be in the zones.conf file
During the wizard I've noticed creation of new zones, which was absent
in the old version of the satellite configuration wizard. I guess that
the issue is there.

When running config validation with icinga daemon -C, debugger points
at the line 'parent = NodeName' in /etc/icinga2/zones.conf:
object Zone "osticket" {
  endpoints = [ "osticket" ]
??  parent = NodeName
}
critical/config: Error: Validation failed for object 'osticket' of
type 'Zone'; Attribute 'parent': Object 'icinga' of type 'Zone' does
not exist.
       
In the newest version, what probably used to be called "icinga" zone,
doesn't exist. There is a zone with an endpoint "icinga" in it, but
it's called master. I will substitute NodeName (that auto changes into
icinga, as I've read in the comments in hosts.conf) with "master" and
see what happens.

*** Error with osticket load service.
[2020-01-07 16:55:04 -0500] critical/config: Error: Validation failed
 for object 'osticket!load' of type 'Service'; Attribute
 'command_endpoint': Checkable with command endpoint requires a
 zone. Please check the troubleshooting documentation.  Location: in
 /etc/icinga2/conf.d/hosts.conf: 61:1-61:21
 /etc/icinga2/conf.d/hosts.conf(59): }
 /etc/icinga2/conf.d/hosts.conf(60):
 /etc/icinga2/conf.d/hosts.conf(61): object Service "load" {
 ^^^^^^^^^^^^^^^^^^^^^ /etc/icinga2/conf.d/hosts.conf(62): import
 "generic-service"



* Reading Icinga documentation to understand Zones problem
https://icinga.com/docs/icinga2/latest/doc/06-distributed-monitoring/#distributed-monitoring-setup-agent-satellite
There are links to other places in Icinga docs. CLI and Installation
are another places that came to my attention.
** Distributed Monitoring
*** Satellites are not Agents!
I've configured Icinga to be the master and Osticket to be the
satellite. However, it seems that the satellite is not a "client" in
this setup. It's more of a command forwarder and servers as a
replacement boss in cases where the master is down or unavailable.

The proper setup would have Osticket as the agent, as there was no
intention for it to forward commands to other instances.


* DONE Learning Git basics to put scripts in a repo
  CLOSED: [2019-12-16 Mon 20:39]
** Most basic Git commands.
I've learned basics of git. It's actually quite simple the n-th time
you are learning it.

Usage of git (learned from ULSAH), when using a local repo, can be
limited to a few commands.
*** git init
To initialize the directory we are in as a repo (creates index and
such)
*** git add .
To add all files inside the local folder (that have changed) to the
next commit. These files sit in index and can be viewed with
*** git status
That will show what is in local file, what is prepared to be committed
and what will not be committed.
*** git commit [-m commit_message]
Will commit the indexed changes into the repo, eventually supplying a
comment.
** Debugging .gitignore
*** git check-ignore -n -v $filename
This allows us to check for why is specific file ignored. It gives us
the source of the rule applied in ignoring the file.
*** git init has to be run AFTER creating .gitignore
Learned from stack overflow. There were many people with the same
problem.
*** global .gitignore file
https://simpleit.rocks/git/make-git-ignore-temporary-files-produced-by-emacs-and-vim-in-all-directories-globally/
A global git ignore file might work too. remember to initialize it
first with `git config --global core.excludesfile ~/.gitignore_global`
** Learning to use git with a remote repo.
To use git with remote repo we use git remote command.
*** git remote add $repo_shortname $repo_url_address.git
will add the repo under the url as a shortname. This can shorten the
amount of writing. If we start a project on our machine by pulling a
remote repo, than the repo of origin will be called as origin.
*** git fetch origin (or remote name)
will fetch all the info about remote branches and such, but not any
files.
*** git pull origin
will pull all the files at origin into our working directory. That's a
prerequisite to put our stuff on the server, but first we need to
merge our branches.
*** git merge --allow-unrelated-histories
will let us merge local branch with the origin/master branch (that is,
the main branch sitting on the origin server). Without the
allow-unrelated-histories there was some error, probably because both
branches that were being merged (local one and the one on the github
server containing only README.md) had no common "history".
*** git branch --set-upstream-to=origin/master
To save myself writing the name of the remote repo and branch for
commits and pushes, I've set the default repo to push to or use. The
origin/master part came out of tabbing out the value. I guess the
origin is the short name of that repo, that was renamed with:
*** git remote rename hub origin
This command was improvised, but worked thanks to git's intuitive
interface. Called the github repo hub at first, but the book was using
origin and it has a nice and professional sound to it.
*** git status -s
A new cooler status, that is a bit more compact. It doesn't give tips
on which git commands you might likely want to use. It uses two
columns in front of filenames to represent their status. First column
is the staging area, and the second column is the working
directory. ?? means an untracked file. M in one of the columns means
either a modified file that has not been staged or that has not been
committed. If a wile was modified, staged and then modified again,
there will be two M's for it's status. An `A` is a new file that has
been added to be tracked after this commit.
*** git diff and git diff --cache
These will show the line by line comparison between the working
directory and the staging area or with (--cache or --staged) option,
the difference between the staging area and last snapshot
(commit). The output of the command includes also a small summary of
the commit to be made, like added/removed lines.
*** git push
will push all the commits made since last updating our data on the
server. It can be many commits and it's best if each commit represents
a one small change to the project. It is especially important when
working with other people, as it will make it easier for people to
accept my pull requests. After running the command the changes are
uploaded and we can see them being moved to the remote server.
* Extras
** DONE Forgot how to connect to a remote server with emacs
   CLOSED: [2019-12-25 Wed 17:46]
tramp and then edit a file as root using sudo to elevate
your privileges you need to re-open file like this:
/ssh:icinga|sudo:icinga:/etc/configfile.conf

** DONE Had to learn MySQL basics to check if databases are loaded
   CLOSED: [2019-12-25 Wed 17:46]
# Showing existing databases:
show databases;
# Creating a new database:
create database $DB_NAME;
# Creating a table inside a database:
> use pets // pick the database to operate on
//use statement tells MySQL to use pets as the default dob to run
//commands on.
> create table cats
(
id INT unsigned NOT NULL AUTO_INCREMENT, # Unique ID for the record
name VARCHAR(150) NOT NULL, # Name of the cat
owner VARCHAR(150) NOT NULL, # Owner of the cat
birth DATE NOT NULL, # Birthday of the cat
PRIMARY KEY (ID) # Make the id the primary key
);

# Check if the table has been created with a SHOW TABLES statement:
SHOW TABLES;











#  LocalWords:  VARCHAR
**** In the end used `mysqlshow | wc -l`
** DONE To pipe output of a command that receives heredocs
   CLOSED: [2019-12-25 Wed 17:46]
we put the pipe after <<EOF, like in this example:
tac <<EOF | awk '{print "awk saw: "$0}'
one
two
three
EOF

This prints:
awk saw: three
awk saw: two
awk saw: one
** DONE Different versions of Icinga and identifying them
   CLOSED: [2020-01-05 Sun 20:18]
Sometimes Icinga will update itself from 2.4 to 2.11. This results in
some differences in the way app works that require addressing.

One difference noticed so far is the change of the configuration
wizard for the icinga. This hurts a little, because I used a heredocs
to configure it. It's not a good idea right now to learn some advanced
bash to make the script read the icinga output and act accordingly. An
easier solution would be to use the tools I already know, or almost
know, grep and awk.

The version of icinga can be checked by running icinga2 --version, and
from that huge wall of text it's possible to extract the required
information. I only need two machines with both the 2.4 and 2.11
versions, to make sure that the conditional will properly distinguish
between the versions. Original icinga VM got "infected" with the new
version of the app. I've created a new VM with IP increased by 1 and
hostname isinga, which has the original 2.5 version.

[vagrant@isinga-test ~]$ sudo icinga2 --version | head -1
icinga2 - The Icinga 2 network monitoring daemon (version: v2.5.4)

[vagrant@icinga ~]$ sudo icinga2 --version | head -1
icinga2 - The Icinga 2 network monitoring daemon (version: 2.11.2-1)

I can get just the last element with awk:
[vagrant@icinga ~]$ sudo icinga2 --version | head -1 | awk '{print $10}'
2.11.2-1)

People in #bash (exactly lopid) told me to use Parameter Expansion
instead. 
<lopid> !pe
<greybot> Parameter Expansion expands parameters: "$foo", "$1". You
can use it to perform string or array operations: "${file%.mp3}",
"${0##*/}", "${files[@]: -4}". They should *always* be quoted. See:
http://mywiki.wooledge.org/BashFAQ/073 and "Parameter Expansion" in
man bash. Also see http://wiki.bash-hackers.org/syntax/pe.

Just read the article that was one of the links at the top of the
linked FAQ answer. Now I know what parameters are. That there are two
types of them, variables and special parameters. Special are used by
bash to inform about some environment state. Variables can be set and
modified by the user. When used in a script, parameters are "expanded"
(also called parameter substitution). In contrary to other programming
languages, what is substituted can still be further modified my shell
(word splitting). Therefore it is much advised to quote every
parameter expansion.

More advanced parameter expansion allows us to have something written
right after the expanded string:
pet=cat
echo "One $pet and many ${pet}s."
>One cat and many cats.

Another thing is modifying the expanded parameter. There are very many
things we can actually do, most basic are:
1. to have a default if the parameter variable is empty or unset,
2. to print only specific part of the string,
3. to print the length of the parameter,
4. delete or substitute a pattern inside of the string, at the end or beginning,
5. remove a pattern from beginning/end,
6. as above, but greedily.

Here we will need to remove or substitute the frontal v from the 2.5
version, and from the end remove the last dot and all after
it. Because of parameter expansion limitations this will require two
expansions.

par=2.11.2-1)
or
par=v2.5.4)
# First expansion to remove v
par="${par/#v/}"
par="${par%.*}"

in a one liner
icinga_ver="$(sudo icinga2 --version | head -1 | awk '{print $10}')";icinga_ver="${icinga_ver/#v/}";icinga_ver="${icinga_ver%.*}";echo $icinga_ver

This returns version of icinga. Either 2.5 or 2.11 (and later this can
be different versions). Not it's just to rename variable par to
something more meaningful and put it inside of an 'if' conditional,
that will let the installation wizard act accordingly to the program's
version and also signal an easy to understand error (explaining that
the value is not a known icinga value).

** DONE Change wagrant to use cache
   CLOSED: [2019-12-25 Wed 17:46]
To avoid annoying wait time everytime wagrant was run, I've made it
create a cache file ~/.globvag. If the file is older than 1800
seconds, wagrant will re-run `vagrant global-status`. The line
if [[ ! (`stat --format=%Y $file` -le $(( `date +%s` - 1800 )) ) ]]
comes from stack overflow question about how to do something if a file
is more than 30 minutes old, found at:
https://stackoverflow.com/a/2005658
** DONE Change update_ssh_config.sh to use cached servers list
   CLOSED: [2019-12-25 Wed 17:46]
*** Finding out how to use sed to delete old entries.
Trying to prepare proper sed expression to match everything between
the Vagrant Projects Start and End comment lines.

sed -n  '/#Vagrant Projects START/,/#Vagrant Projects END/ p'
 ~/.ssh/config

*** Got an idea to save the edited place with sed.
While reading the docs I've found that like 'p' prints the currently
edited line, the '=' commands prints the number of the currently
edited line. Can use it to have the changes in place instead of
appending them to the end of the file.

*** Arrays with names and hashes of servers
***** Temporarily I will use the same servers_list file.
# Here I need to get a new list of servers, preferably in an array of
# either server names (what I will use and what ssh_config needs, or
# vagrant server hashes (which wagrant command supplies to
# vagrant). Another array, preferably associative with key-values -
# server-hash -> name or vice versa.
# Let's say it(the arrary)'s called servers

***** I'm a little sleep deprived today, so this should be checked when I'm
in better shape.
Read up on arrays. Tried the "Learning Bash" book bought in one of
Humble Bundles. First code example from the chapter on arrays was
something that Should do it's job in my script. The example shows
initializing of an array with output of cut run on /etc/passwd (which
contains data on users on system, including their user_id number and
their username). A for loop is run on the cut output, where each
iteration of the loop puts a username into an array element with
user_id as an index. This is the example:

for i in $(cut -f 1,3 -d: /etc/passwd) ; do
  array[${i#*:}]=${i%:*}
done

Arrays seem quite counter intuitive, best would be to test the code as
it's being written.

In that example a for is iterated over lines of output from cut. Cut
cuts out fields number 1 and three (uid and username), using `:` as a
separator. All taken from /etc/passwd. There is a parameter expansion
run on this output. ${i#*:} gives value of i, with the initial part
removed until the first `:`. This gives us uuid without the trailing
username. Second expansion, ${i%:*} gives us the cut out string minus
the trailing :* which matches all until first `:` counted from the end
of the string.

***** I've played a little with the terminal, 
for i in $(vagrant global-status --prune | grep running | cut 
-f6 -d' ') ; do arrayX+=( ${i##*/} ); done 

this will create an array (using add a new element to array that is
array+=(new_element)). Could be wise to unset the array first, just in
case there already was an array with the same name.

unset array

This will yield an array name arrayX with the names of all running
servers. This is enough to populate the .ssh/config file.

***** Handling Zombie VMs. 
There is one edge case: Sometimes vagrant reports VM as running, even
though it's not. To avoid errors we can check VM's status with wagrant
status called on it's name, and then grep for "running" existing in
the output. This coupled with an if statement calling "continue"
special word will skip the server that was reported as running in
vagrant global-status if the server is not actually running.
 
*** Reordered script a little and modified it to ease debugging

*** Reworking adding new entries into the .ssh/config

# Adding new entries can be done two ways. Since now I can use sed 'i'
# function, I could just insert each server config batch in the right
# place. Instead decided to upgrade the old method. The for loop can
# be inside the curly braces, so that the block init and close lines
# can be written only ones. Need to trace the pointer somehow. Started
# playing with where it ends variable, but then remembered, that I'm
# still reading the unchanged ssh config and writing into a temp ssh
# config.

#Add new entries
{ head -$(($where_it_started - 1)) ~/.ssh/config
echo "#Vagrant Projects START"
for sys in ${servers[*]}
do
    printf "$( wagrant ssh-config "$sys" | sed "s/Host default/Host $sys/" )\n\n";
done
 tail -n +$where_it_started ~/.ssh/config; } > ~/.ssh/config-tmp
    mv ~/.ssh/config-tmp ~/.ssh/config
    
*** Debugging
**** Seems like backing up works properly now, using %s/3600
**** Checking if server's list gets created properly.
Forgot that there have to be running vagrant servers for the thing to
run.

It wasn't, the command:
vagrant global-status | grep running | cut -f7 -d' '
is not reliable. Rewriting using awk.

Now it works.
**** There was an error with marking down the beggining of block
Somehow there were two start and two end lines. Will make the script
check how many of them are there in the config. If there are more than
1 of each, the script will stop and report the error.
Now the value written is correct, and there wont be another case with
double start lines.

**** Everything works fine. Changed script's description.
** DONE Learned how to use commit signing (git commit -S)
   CLOSED: [2020-01-07 Tue 22:09]
*** First looked for tutorials. Github's tutorial was easiest to follow.
I found it when clicked "verified" tag on a commit in some project's
commit history.
*** Generated a new key
The passphrase was most difficult to get, because gpg's password
strength tester didn't like my long letter only passwords.
*** Added the new key hash as a git --global config variable.
*** Added the new 
** Disk alert from Icinga
There is an annoying alert saying that space on /vagrant partition is
critically low. /vagrant is where the host vagrant project directory
is mounted.
To avoid receiving that alert we can tell icinga to ignore the
/vagrant partition, by modifying the osticket Host stanza in
hosts.conf on master server:
  vars.disk_partitions_excluded = [ "/vagrant" ]

full stanza looks like this:
object Host "osticket" {
  import "generic-host"
  address = "10.23.45.20"
  vars.os = "Linux"
  vars.disk_partitions_excluded = [ "/vagrant" ]

}
